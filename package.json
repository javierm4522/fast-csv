{
  "name": "fast-csv",
  "version": "0.2.2",
  "description": "CSV parser and writer",
  "main": "index.js",
  "scripts": {
    "test": "grunt"
  },
  "repository": {
    "type": "git",
    "url": "git@github.com:C2FO/fast-csv.git"
  },
  "keywords": [
    "csv",
    "parser",
    "fast",
    "writer",
    "csv writer",
    "CSV"
  ],
  "homepage": "http://c2fo.github.com/fast-csv/index.html",
  "author": {
    "name": "Doug Martin"
  },
  "license": "MIT",
  "devDependencies": {
    "it": "~0.2.6",
    "grunt-it": "~0.3.1",
    "grunt": "~0.4.1",
    "grunt-contrib-jshint": "~0.4.3"
  },
  "engines": {
    "node": ">=0.10"
  },
  "readme": "<a name=\"top\"></a>\n\n\n  [![build status](https://secure.travis-ci.org/C2FO/fast-csv.png)](http://travis-ci.org/C2FO/fast-csv)\n# Fast-csv\n\nThis is a library that provides CSV parsing and formatting.\n\n**NOTE** As of v0.2.0 `fast-csv` supports multi-line values.\n\n## Installation\n\n`npm install fast-csv`\n\n## Usage\n\n### Parsing\n\nAll methods accept the following `options`\n\n* `headers=false`: Ste to true if you expect the first line of your `CSV` to contain headers, alternatly you can specify an array of headers to use.\n* `ignoreEmpty=false`: If you wish to ignore empty rows.\n* `delimiter=','`: If your data uses an alternate delimiter such as `;` or `\\t`.\n   * **NOTE** When specifying an alternate `delimiter` you may only pass in a single character delimeter\n* `quote='\"'`: The character to use to escape values that contain a delimeter.\n* `escape='\"'`: The character to use when escaping a value that is `quoted` and contains a `quote` character.\n    * `i.e`: 'First,\"Name\"' => '\"First,\"\"name\"\"\"'\n* The following are options for parsing only.\n  * `trim=false`: If you want to trim all values parsed set to true.\n  * `rtrim=false`: If you want to right trim all values parsed set to true.\n  * `ltrim=false`: If you want to left trim all values parsed set to true.\n\n\n**events**\n\n`parse-error`: Emitted if there was an error parsing a row.\n`record`: Emitted when a record is parsed.\n`data-invalid`: Emitted if there was invalid row encounted, **only emitted if the `validate` function is used**.\n`data`: Emitted with the `stringified` version of a record.\n\n**([options])**\n\nIf you use `fast-csv` as a function it returns a transform stream that can be piped into.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\nvar csvStream = csv()\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\nstream.pipe(csvStream);\n```\n\n**`.fromPath(path[, options])**\n\nThis method parses a file from the specified path.\n\n```javascript\nvar csv = require(\"fast-csv\");\n\ncsv\n .fromPath(\"my.csv\")\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\n**`.fromString(string[, options])**\n\nThis method parses a string\n\n```javascript\nvar csv = require(\"fast-csv\");\n\nvar CSV_STRING = 'a,b\\n' +\n                 'a1,b1\\n' +\n                 'a2,b2\\n';\n\ncsv\n .fromPath(CSV_STRING, {headers: true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\n**`.fromStream(stream[, options])**\n\nThis accepted a readable stream to parse data from.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv()\n .fromStream(stream)\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\nIf you expect the first line your csv to headers you may pass a headers option in. Setting the headers option will\ncause change each row to an object rather than an array.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv()\n .fromStream(stream, {headers : true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\nYou may alternatively pass an array of header names which must match the order of each column in the csv, otherwise\nthe data columns will not match.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream, {headers : [\"firstName\", \"lastName\", \"address\"]})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\nIf your data may include empty rows, the sort Excel might include at the end of the file for instance, you can ignore\nthese by including the `ignoreEmpty` option.\n\nAny rows consisting of nothing but empty strings and/or commas will be skipped, without emitting a 'data' or 'error' event.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream, {ignoreEmpty: true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Validating\n\nYou can validate each row in the csv by providing a validate handler. If a row is invalid then a `data-invalid` event\nwill be emitted with the row and the index.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv(\n .fromStream(stream, {headers : true})\n .validate(function(data){\n     return data.age < 50; //all persons must be under the age of 50\n })\n .on(\"data-invalid\", function(data){\n     //do something with invalid row\n })\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Transforming\n\nYou can transform data by providing in a transform function. What is returned from the transform function will\nbe provided to validate and emitted as a row.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream)\n .transform(function(data){\n     return data.reverse(); //reverse each row.\n })\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Formatting\n\n`fast-csv` also allows to you to create create a `CSV` from data.\n\nFormatting accepts the same options as parsing.\n*\n**Writing Data**\n\nEach of the following methods accept an array of values to be written, however each value must be an `array` of `array`s or `object`s.\n\n**`write(arr[, options])`**\n\nCreate a readable stream to read data from.\n\n```javascript\nvar ws = fs.createWritableStream(\"my.csv\");\ncsv\n   .write([\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true})\n   .pipe(ws);\n```\n\n```javascript\nvar ws = fs.createWritableStream(\"my.csv\");\ncsv\n   .write([\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .pipe(ws);\n```\n\n**`writeToStream(stream,arr[, options])`**\n\nWrite an array of values to a `WritableStream`\n\n```javascript\ncsv\n   .writeToStream(fs.createWritableStream(\"my.csv\"), [\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true});\n```\n\n```javascript\ncsv\n   .writeToStream(fs.createWritableStream(\"my.csv\"), [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .pipe(ws);\n```\n\n**`writeToPath(arr[, options])`**\n\nWrite an array of values to the specified path\n\n```javascript\ncsv\n   .writeToPath(\"my.csv\", [\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true})\n   .on(\"finish\", function(){\n       console.log(\"done!\");\n   });\n```\n\n```javascript\ncsv\n   .writeToStream(\"my.csv\", [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .on(\"finish\", function(){\n      console.log(\"done!\");\n   });\n```\n\n**`writeToString(arr[, options])`**\n\n```javascript\ncsv.writeToString([\n   [\"a\", \"b\"],\n   [\"a1\", \"b1\"],\n   [\"a2\", \"b2\"]\n], {headers: true}); //\"a,b\\na1,b1\\na2,b2\\n\"\n```\n\n```javascript\ncsv.writeToString([\n   {a: \"a1\", b: \"b1\"},\n   {a: \"a2\", b: \"b2\"}\n], {headers: true}); //\"a,b\\na1,b1\\na2,b2\\n\"\n```\n\n## Benchmarks\n\n`Parsing 20000 records AVG over 3 runs`\n\n```\nfast-csv: 198.67ms\ncsv:      525.33ms\n```\n\n`Parsing 50000 records AVG over 3 runs`\n\n```\nfast-csv: 441.33ms\ncsv:      1291ms\n```\n\n`Parsing 100000 records AVG over 3 runs`\n\n```\nfast-csv: 866ms\ncsv:      2773.33ms\n```\n\n`Parsing 1000000 records AVG over 3 runs`\n\n```\nfast-csv: 8562.67ms\ncsv:      30030.67ms\n```\n\n## License\n\nMIT <https://github.com/C2FO/fast-csv/raw/master/LICENSE>\n\n##Meta\n* Code: `git clone git://github.com/C2FO/fast-csv.git`\n* Website: <http://c2fo.com>\n* Twitter: [http://twitter.com/c2fo](http://twitter.com/c2fo) - 877.465.4045\n\n##Namespaces\n\n\n\n\n\n##Classes\n\n\n\n\n\n\n\n\n\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/C2FO/fast-csv/issues"
  },
  "_id": "fast-csv@0.2.2",
  "dist": {
    "shasum": "d08dbdea7efb107433ee6fde1627d8a81e7329d5"
  },
  "_resolved": "git://github.com/at0g/fast-csv#94fff73fd962254163f41ec8b206a2643ee03455",
  "_from": "fast-csv@git://github.com/javierm4522/fast-csv"
}
